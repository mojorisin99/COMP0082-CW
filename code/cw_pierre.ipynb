{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "37bb19f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "#model_def.py\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f62db",
   "metadata": {},
   "source": [
    "## Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f13986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "blind_path = \"../data/blind.fasta.txt\"\n",
    "cyto_path = \"../data/cyto.fasta.txt\"\n",
    "mito_path = \"../data/mito.fasta.txt\"\n",
    "nucleus_path = \"../data/nucleus.fasta.txt\"\n",
    "other_path = \"../data/other.fasta.txt\"\n",
    "secreted_path = \"../data/secreted.fasta.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aa833f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(file):\n",
    "    \"\"\"\n",
    "    This function takes an unstructured fasta file and outputs a dictionary of the sequences\n",
    "    Input: - fasta file\n",
    "    Output: - dict with keys (sequence header) and values (sequence)\n",
    "    \"\"\"\n",
    "    sequences = {}\n",
    "    with open(file, 'r') as f:\n",
    "        header = \"\"\n",
    "        sequence = \"\"\n",
    "        for line in f:\n",
    "            #in a fasta file the first character is a > sign\n",
    "            if line[0] == \">\":\n",
    "                if header:\n",
    "                    sequences[header] = sequence\n",
    "                header = line[1:].strip()\n",
    "                sequence = \"\"\n",
    "            else:\n",
    "                sequence += line.strip()\n",
    "        sequences[header] = sequence\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43ce555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequences</th>\n",
       "      <th>cyto</th>\n",
       "      <th>mito</th>\n",
       "      <th>nucleus</th>\n",
       "      <th>other</th>\n",
       "      <th>secreted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTADAGF...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MALEPIDYTTHSREIDAEYLKIVRGSDPDTTWLIISPNAKKEYEPE...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNQIEPGVQYNYVYDEDEYMIQEEEWDRDLLLDPAWEKQQRKTFTA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSEEPTPVSGNDKQLLNKAWEITQKKTFTAWCNSHLRKLGSSIEQI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MGDWMTVTDPGLSSESKTISQYTSETKMSPSSLYSQQVLCSSIPLS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11219</th>\n",
       "      <td>MIPNITQLKTAALVMLFAGQALSGPVESRQASESIDAKFKAHGKKY...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11220</th>\n",
       "      <td>MLRKLVTGALAAALLLSGQSNAQNACQQTQQLSGGRTINNKNETGN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>MIFHQFYSILILCLIFPNQVVQSDKERQDWIPSDYGGYMNPAGRSD...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>MKFQVVLSALLACSSAVVASPIENLFKYRAVKASHSKNINSTLPAW...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>MLTVALLALLCASASGNAIQARSSSYSGEYGGGGGKRFSHSGNQLD...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11224 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sequences  cyto  mito  nucleus  \\\n",
       "0      MGQQVGRVGEAPGLQQPQPRGIRGSSAARPSGRRRDPAGRTADAGF...     1     0        0   \n",
       "1      MALEPIDYTTHSREIDAEYLKIVRGSDPDTTWLIISPNAKKEYEPE...     1     0        0   \n",
       "2      MNQIEPGVQYNYVYDEDEYMIQEEEWDRDLLLDPAWEKQQRKTFTA...     1     0        0   \n",
       "3      MSEEPTPVSGNDKQLLNKAWEITQKKTFTAWCNSHLRKLGSSIEQI...     1     0        0   \n",
       "4      MGDWMTVTDPGLSSESKTISQYTSETKMSPSSLYSQQVLCSSIPLS...     1     0        0   \n",
       "...                                                  ...   ...   ...      ...   \n",
       "11219  MIPNITQLKTAALVMLFAGQALSGPVESRQASESIDAKFKAHGKKY...     0     0        0   \n",
       "11220  MLRKLVTGALAAALLLSGQSNAQNACQQTQQLSGGRTINNKNETGN...     0     0        0   \n",
       "11221  MIFHQFYSILILCLIFPNQVVQSDKERQDWIPSDYGGYMNPAGRSD...     0     0        0   \n",
       "11222  MKFQVVLSALLACSSAVVASPIENLFKYRAVKASHSKNINSTLPAW...     0     0        0   \n",
       "11223  MLTVALLALLCASASGNAIQARSSSYSGEYGGGGGKRFSHSGNQLD...     0     0        0   \n",
       "\n",
       "       other  secreted  \n",
       "0          0         0  \n",
       "1          0         0  \n",
       "2          0         0  \n",
       "3          0         0  \n",
       "4          0         0  \n",
       "...      ...       ...  \n",
       "11219      0         1  \n",
       "11220      0         1  \n",
       "11221      0         1  \n",
       "11222      0         1  \n",
       "11223      0         1  \n",
       "\n",
       "[11224 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the dictionary of sequences for each location\n",
    "blind_sequences = read_fasta(blind_path)\n",
    "cyto_sequences = read_fasta(cyto_path)\n",
    "mito_sequences = read_fasta(mito_path)\n",
    "nucleus_sequences = read_fasta(nucleus_path)\n",
    "other_sequences = read_fasta(other_path)\n",
    "secreted_sequences = read_fasta(secreted_path)\n",
    "\n",
    "df_cyto = pd.DataFrame.from_dict(cyto_sequences, orient='index', columns=['Sequences'])\n",
    "df_cyto = df_cyto.reset_index().rename(columns={'index':'Label'})\n",
    "df_cyto['Label'] = 'cyto'\n",
    "\n",
    "df_mito = pd.DataFrame.from_dict(mito_sequences, orient='index', columns=['Sequences'])\n",
    "df_mito = df_mito.reset_index().rename(columns={'index':'Label'})\n",
    "df_mito['Label'] = 'mito'\n",
    "\n",
    "df_nucleus = pd.DataFrame.from_dict(nucleus_sequences, orient='index', columns=['Sequences'])\n",
    "df_nucleus = df_nucleus.reset_index().rename(columns={'index':'Label'})\n",
    "df_nucleus['Label'] = 'nucleus'\n",
    "\n",
    "df_other = pd.DataFrame.from_dict(other_sequences, orient='index', columns=['Sequences'])\n",
    "df_other = df_other.reset_index().rename(columns={'index':'Label'})\n",
    "df_other['Label'] = 'other'\n",
    "\n",
    "df_secreted = pd.DataFrame.from_dict(secreted_sequences, orient='index', columns=['Sequences'])\n",
    "df_secreted = df_secreted.reset_index().rename(columns={'index':'Label'})\n",
    "df_secreted['Label'] = 'secreted'\n",
    "\n",
    "df = pd.concat([df_cyto, df_mito, df_nucleus, df_other, df_secreted], axis=0).reset_index()\n",
    "# Display the DataFrame\n",
    "#df['encoded_cat'] = df['Label'].astype('category').cat.codes\n",
    "#df.drop(columns={'index', 'Label'}, inplace=True)\n",
    "\n",
    "#result = df.to_dict('records')\n",
    "\n",
    "one_hot = pd.get_dummies(df['Label'])\n",
    "df = pd.concat([df, one_hot], axis=1)\n",
    "df.drop(columns={'index', 'Label'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd60e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = ['cyto', 'mito', 'nucleus','other', 'secreted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50758174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, validation_set = False):  \n",
    "    \n",
    "    #train test split of dataset \n",
    "    train_size = 0.8\n",
    "    train_df=df.sample(frac=train_size,random_state=200)\n",
    "    test_df=df.drop(train_df.index).reset_index(drop=True)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    \n",
    "    if validation_set:\n",
    "        #split the train further with a validation dataset\n",
    "        train_size = 0.8\n",
    "        train2_df = train_df.sample(frac=train_size, random_state=200)\n",
    "        val_df = train_df.drop(train2_df.index).reset_index(drop=True)\n",
    "        train2_df = train2_df.reset_index(drop=True)\n",
    "    \n",
    "        return train2_df, test_df, val_df\n",
    "   \n",
    "    return train_df, test_df\n",
    "\n",
    "train2_df, test_df, val_df = train_test_split(df, validation_set = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558eef7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8c30c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd_localization'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f1ed57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinSequenceDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        single_row = self.data.iloc[item]\n",
    "        sequence = single_row['Sequences']\n",
    "        target = single_row[target_list]\n",
    "        #target[['cyto', 'mito', 'nucleus','other', 'secreted']] = target[['cyto', 'mito', 'nucleus','other', 'secreted']].astype(int)\n",
    "\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sequence,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "          'protein_sequence': sequence,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27f21706",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinSequenceDataset(train_df, tokenizer = tokenizer, max_len = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "27ed7499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein_sequence': 'MLPGLAAAAAHRCSWSSLCRLRLRCRAAACNPSDRQEWQNLVTFGSFSNMVPCSHPYIGTLSQVKLYSTNVQKEGQGSQTLRVEKVPSFETAEGIGTELKAPLKQEPLQVRVKAVLKKREYGSKYTQNNFITGVRAINEFCLKSSDLEQLRKIRRRSPHEDTESFTVYLRSDVEAKSLEVWGSPEALAREKKLRKEAEIEYRERLFRNQKILREYRDFLGNTKPRSRTASVFFKGPGKVVMVAICINGLNCFFKFLAWIYTGSASMFSEAIHSLSDTCNQGLLALGISKSVQTPDPSHPYGFSNMRYISSLISGVGIFMMGAGLSWYHGVMGLLHPQPIESLLWAYCILAGSLVSEGATLLVAVNELRRNARAKGMSFYKYVMESRDPSTNVILLEDTAAVLGVIIAATCMGLTSITGNPLYDSLGSLGVGTLLGMVSAFLIYTNTEALLGRSIQPEQVQRLTELLENDPSVRAIHDVKATDLGLGKVRFKAEVDFDGRVVTRSYLEKQDFDQMLQEIQEVKTPEELETFMLKHGENIIDTLGAEVDRLEKELKKRNPEVRHVDLEIL',\n",
       " 'input_ids': tensor([2, 1, 3,  ..., 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'targets': tensor([0, 0, 1, 0, 0])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "513a786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, test_df,val_df,  tokenizer, batch_size=32, max_len=1500):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.val_df = val_df\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = ProteinSequenceDataset(self.train_df, self.tokenizer, self.max_len)\n",
    "        self.test_dataset = ProteinSequenceDataset(self.test_df, self.tokenizer, self.max_len)\n",
    "        self.val_dataset = ProteinSequenceDataset(self.val_df, self.tokenizer, self.max_len)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True,num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,batch_size=1,num_workers=4)    \n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset,batch_size=1,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5062d180",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 1500\n",
    "\n",
    "data_module = ProteinDataModule(\n",
    "    train_df, \n",
    "    test_df,\n",
    "    val_df,\n",
    "    tokenizer, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_len = MAX_LENGTH\n",
    ")\n",
    "\n",
    "data_module.setup() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0bebf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd_localization'\n",
    "\n",
    "class ProteinClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_classes: int, steps_per_epoch=None, n_epochs=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                        nn.Linear(self.bert.config.hidden_size, n_classes),\n",
    "                                        nn.Tanh())\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.n_epochs = n_epochs\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, targets=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        output = self.classifier(output.pooler_output)\n",
    "        output = torch.sigmoid(output)\n",
    "        loss = 0\n",
    "        if targets is not None:\n",
    "            loss = self.criterion(output, targets)\n",
    "        return loss, output\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, targets)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return {\n",
    "            \"loss\": loss,\n",
    "            \"predictions\": outputs,\n",
    "            \"targets\": targets\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, targets)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        targets = batch[\"targets\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, targets)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        \n",
    "        for output in outputs:\n",
    "            for out_labels in output[\"targets\"].detach().cpu():\n",
    "                targets.append(out_labels)\n",
    "\n",
    "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
    "                predictions.append(out_predictions)\n",
    "        print(\"#####\")\n",
    "        targets = torch.stack(targets).int()\n",
    "        predictions = torch.stack(predictions)\n",
    "\n",
    "        for i, name in enumerate(Classes):\n",
    "            roc_score = torchmetrics.AUROC(predictions[:, i], labels[:, i])\n",
    "            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", roc_score, self.current_epoch)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=2e-5)\n",
    "        warmup_steps = self.steps_per_epoch // 3\n",
    "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a0b91e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd_localization were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dm = ProteinDataModule(\n",
    "    train_df, \n",
    "    test_df,\n",
    "    val_df,\n",
    "    tokenizer, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_len = MAX_LENGTH\n",
    ")\n",
    "\n",
    "model = ProteinClassifier(\n",
    "    n_classes=len(target_list), \n",
    "    steps_per_epoch=len(train_df)//BATCH_SIZE, \n",
    "    n_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "dcdfef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "45c86fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type       | Params\n",
      "------------------------------------------\n",
      "0 | bert       | BertModel  | 419 M \n",
      "1 | classifier | Sequential | 5.1 K \n",
      "2 | criterion  | BCELoss    | 0     \n",
      "------------------------------------------\n",
      "419 M     Trainable params\n",
      "0         Non-trainable params\n",
      "419 M     Total params\n",
      "1,679.745 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cba6355d9e4f5abedbf5ea487a6633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/pierredemetz/.pyenv/versions/3.8.12/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/pierredemetz/.pyenv/versions/3.8.12/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'ProteinSequenceDataset' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33039285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4e2df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0462b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dcab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd_localization'\n",
    "class ProteinClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ProteinClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.classifier = nn.Sequential(nn.Dropout(p=0.2),\n",
    "                                        nn.Linear(self.bert.config.hidden_size, n_classes),\n",
    "                                        nn.Tanh())\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.bert(\n",
    "          input_ids=input_ids,\n",
    "          attention_mask=attention_mask\n",
    "        )\n",
    "        return self.classifier(output.pooler_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
