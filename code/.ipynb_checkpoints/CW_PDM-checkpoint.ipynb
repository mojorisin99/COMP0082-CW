{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c4004a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4d3792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from model_fct import ProteinClassifier, ProteinDataModule, ProteinSequenceDataset\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from pytorch_lightning.accelerators import MPSAccelerator\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy, MultilabelF1Score\n",
    "from torchmetrics import Recall, Precision\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#from pytorch_lightning.metrics.sklearns import Accuracy\n",
    "\n",
    "import torchvision\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd3cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66153464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train_df.pkl')\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "val_df = pd.read_pickle('val_df.pkl')\n",
    "blind_df = pd.read_pickle('blind_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38e2fe",
   "metadata": {},
   "source": [
    "## Logger and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7642051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_testube_logger() -> CSVLogger:\n",
    "    \"\"\" Function that sets the TestTubeLogger to be used. \"\"\"\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "\n",
    "    return CSVLogger(\n",
    "        save_dir=\"experiments/\",\n",
    "        version=dt_string,\n",
    "        name=\"lightning_logs\",\n",
    "    )\n",
    "\n",
    "logger = setup_testube_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5250ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(\n",
    "    logger.save_dir,\n",
    "    logger.name,\n",
    "    f\"version_{logger.version}\",\n",
    "    \"checkpoints\",\n",
    ")\n",
    "\n",
    "c = ModelCheckpoint(\n",
    "    dirpath=ckpt_path + \"/\" + \"tanh_3epochs\",\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9502b40",
   "metadata": {},
   "source": [
    "## Set up experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e81b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['cyto', 'mito', 'nucleus','other', 'secreted']\n",
    "PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd_localization'\n",
    "#PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=False)\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_LENGTH = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e14697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dm = ProteinDataModule(\n",
    "    train_df, \n",
    "    test_df,\n",
    "    val_df,\n",
    "    blind_df,\n",
    "    tokenizer, \n",
    "    target_list=TARGETS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_len = MAX_LENGTH\n",
    ")\n",
    "\n",
    "model = ProteinClassifier(\n",
    "    n_classes=5,\n",
    "    target_list=TARGETS,\n",
    "    steps_per_epoch=len(train_df)//BATCH_SIZE, \n",
    "    n_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9866f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS,\n",
    "                     logger=logger,\n",
    "                     accelerator='mps',\n",
    "                     #callbacks = checkpoint_callback\n",
    "                     default_root_dir='experiments/lightning_logs'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3d0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | bert       | BertModel        | 419 M \n",
      "1 | classifier | Sequential       | 5.1 K \n",
      "2 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "419 M     Trainable params\n",
      "0         Non-trainable params\n",
      "419 M     Total params\n",
      "1,679.745 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.00\n",
      "the precision is 0.00\n",
      "the recall is 0.00\n",
      "the f1 is 0.00\n",
      "   precision  recall   f1  accuracy  num_samples\n",
      "0        0.0     0.0  0.0       0.0            1\n",
      "1        0.0     0.0  0.0       1.0            0\n",
      "2        0.0     0.0  0.0       0.0            1\n",
      "[[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95b2d07eea940fdad7a384e487b5c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(dataloaders=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d297d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the given matrix\n",
    "classes = TARGETS\n",
    "matrix = np.array([[475, 21, 94, 8, 8],\n",
    "                   [46, 203, 7, 6, 1],\n",
    "                   [153, 7, 473, 6, 3],\n",
    "                   [18, 18, 3, 373, 1],\n",
    "                   [23, 3, 1, 5, 289]])\n",
    "\n",
    "# Initialize the confusion matrix with zeros\n",
    "confusion_matrix = np.zeros((len(classes), len(classes)))\n",
    "\n",
    "# Fill the confusion matrix with values from the given matrix\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        confusion_matrix[i, j] = matrix[i, j]\n",
    "\n",
    "# Normalize the confusion matrix if needed\n",
    "#confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.matshow(confusion_matrix, cmap=plt.cm.Oranges)\n",
    "\n",
    "# Set labels for x and y axis\n",
    "ax.set_xticklabels([''] + classes, fontsize=12)\n",
    "ax.set_yticklabels([''] + classes, fontsize=12)\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('Confusion Matrix', fontsize=16)\n",
    "ax.set_xlabel('Predicted Label', fontsize=14)\n",
    "ax.set_ylabel('True Label', fontsize=14)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Add text annotations to the confusion matrix\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        ax.text(j, i, int(confusion_matrix[i, j]), ha='center', va='center', color='white', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n",
    "plt.savefig('../Confusion_Matrix_Testing_Set.png', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23155e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64c008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b6400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281300ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dcaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# example target and output lists\n",
    "targets = [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n",
    "outputs = [0, 1, 1, 3, 4, 0, 2, 2, 3, 4]\n",
    "\n",
    "def classification_metrics(targets, outputs):\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(targets, outputs)\n",
    "    \n",
    "    # compute total number of samples for each class\n",
    "    total_per_class = np.sum(cm, axis=1)\n",
    "    \n",
    "    # compute number of correctly classified samples for each class\n",
    "    correct_per_class = np.diagonal(cm)\n",
    "    \n",
    "    # compute precision, recall, and f1 score for each class\n",
    "    p, r, f1, _ = precision_recall_fscore_support(targets, outputs, average=None)\n",
    "    \n",
    "    # compute accuracy for each class\n",
    "    accuracy_per_class = np.divide(correct_per_class, total_per_class, where=total_per_class!=0)\n",
    "    \n",
    "    # create a dataframe to hold the results\n",
    "    df = pd.DataFrame({\n",
    "        'precision': p,\n",
    "        'recall': r,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy_per_class,\n",
    "        'num_samples': total_per_class\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print(cm)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_metrics(targets, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define your target and output lists\n",
    "targets = [0, 1, 2, 3, 4]\n",
    "outputs = [1, 1, 2, 3, 4]\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(targets, outputs)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(targets, outputs)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb93a80",
   "metadata": {},
   "source": [
    "## Testing and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change for best one - manually check which one is the best\n",
    "best_checkpoint_path = '/Users/pierredemetz/UCL_work/COMP0082-CW/code/experiments/lightning_logs/20-02-2023--21-58-19/checkpoints/epoch=1-step=14366.ckpt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(resume_from_checkpoint=best_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ac5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(model, dm)\n",
    "results = []\n",
    "for item in outputs:\n",
    "    tensor = item[1]\n",
    "    max_prob, max_target_idx = torch.max(tensor, dim=1)\n",
    "    max_target = TARGETS[max_target_idx]\n",
    "    results.append((max_prob.item(), max_target))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef259d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd25071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ca22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80687ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc613e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee6a125a",
   "metadata": {},
   "source": [
    "## LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca1b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_list = ['cyto', 'mito', 'nucleus','other', 'secreted']\n",
    "n_classes = 5\n",
    "\n",
    "protein_classifier = ProteinClassifier(n_classes, target_list)\n",
    "protein_classifier = protein_classifier.load_from_checkpoint(\n",
    "    checkpoint_path=best_checkpoint_path,\n",
    "    n_classes=n_classes,\n",
    "    target_list=target_list\n",
    ")\n",
    "\n",
    "protein_classifier.eval()\n",
    "protein_classifier.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab351ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "  \"seq\": \"M S T D T G V S L P S Y E E D Q G S K L I R K A K E A P F V P V G I A G F A A I V A Y G L Y K L K S R G N T K M S I H L I H M R V A A Q G F V V G A M T V G M G Y S M Y R E F W A K P K P\",\n",
    "}\n",
    "\n",
    "predictions = protein_classifier.predict_step(sample, batch_idx=0)\n",
    "\n",
    "print(\"Sequence Localization Ground Truth is: {} - prediction is: {}\".format('Mitochondrion',predictions['predicted_label']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae99666",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e991be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d55e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "sequence_Example = \"A E T C Z A O\"\n",
    "sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n",
    "encoded_input = tokenizer(sequence_Example, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6245952",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92310d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_registry=torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelertorch.backends.mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPSAccelerator.register_accelerators(device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f450e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511a9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
