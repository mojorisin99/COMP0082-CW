{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57c4004a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be4d3792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from model_fct import ProteinClassifier, ProteinDataModule, ProteinSequenceDataset\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from pytorch_lightning.accelerators import MPSAccelerator\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy, MultilabelF1Score\n",
    "from torchmetrics import Recall, Precision\n",
    "\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "#from pytorch_lightning.metrics.sklearns import Accuracy\n",
    "\n",
    "import torchvision\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bd3cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arm'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import platform\n",
    "platform.processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66153464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train_df.pkl')\n",
    "test_df = pd.read_pickle('test_df.pkl')\n",
    "val_df = pd.read_pickle('val_df.pkl')\n",
    "blind_df = pd.read_pickle('blind_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38e2fe",
   "metadata": {},
   "source": [
    "## Logger and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7642051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_testube_logger() -> CSVLogger:\n",
    "    \"\"\" Function that sets the TestTubeLogger to be used. \"\"\"\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime(\"%d-%m-%Y--%H-%M-%S\")\n",
    "\n",
    "    return CSVLogger(\n",
    "        save_dir=\"experiments/\",\n",
    "        version=dt_string,\n",
    "        name=\"lightning_logs\",\n",
    "    )\n",
    "\n",
    "logger = setup_testube_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5250ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = os.path.join(\n",
    "    logger.save_dir,\n",
    "    logger.name,\n",
    "    f\"version_{logger.version}\",\n",
    "    \"checkpoints\",\n",
    ")\n",
    "\n",
    "c = ModelCheckpoint(\n",
    "    dirpath=ckpt_path + \"/\" + \"tanh_3epochs\",\n",
    "    verbose=True,\n",
    "    monitor='val_acc',\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9502b40",
   "metadata": {},
   "source": [
    "## Set up experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e81b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['cyto', 'mito', 'nucleus','other', 'secreted']\n",
    "PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd_localization'\n",
    "#PRE_TRAINED_MODEL_NAME = 'Rostlab/prot_bert_bfd'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=False)\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 1\n",
    "MAX_LENGTH = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e14697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dm = ProteinDataModule(\n",
    "    train_df, \n",
    "    test_df,\n",
    "    val_df,\n",
    "    blind_df,\n",
    "    tokenizer, \n",
    "    target_list=TARGETS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_len = MAX_LENGTH\n",
    ")\n",
    "\n",
    "model = ProteinClassifier(\n",
    "    n_classes=5,\n",
    "    target_list=TARGETS,\n",
    "    steps_per_epoch=len(train_df)//BATCH_SIZE, \n",
    "    n_epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9866f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=EPOCHS,\n",
    "                     logger=logger,\n",
    "                     accelerator='mps',\n",
    "                     #callbacks = checkpoint_callback\n",
    "                     default_root_dir='experiments/lightning_logs'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c3d0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | bert       | BertModel        | 419 M \n",
      "1 | classifier | Sequential       | 5.1 K \n",
      "2 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "419 M     Trainable params\n",
      "0         Non-trainable params\n",
      "419 M     Total params\n",
      "1,679.745 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.00\n",
      "the precision is 0.00\n",
      "the recall is 0.00\n",
      "the f1 is 0.00\n",
      "   precision  recall   f1  accuracy  num_samples\n",
      "0        0.0     0.0  0.0       0.0            1\n",
      "1        0.0     0.0  0.0       1.0            0\n",
      "2        0.0     0.0  0.0       0.0            1\n",
      "[[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95b2d07eea940fdad7a384e487b5c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.76\n",
      "the precision is 0.80\n",
      "the recall is 0.77\n",
      "the f1 is 0.78\n",
      "   precision    recall        f1  accuracy  num_samples\n",
      "0   0.585516  0.753968  0.659150  0.753968          504\n",
      "1   0.746269  0.753769  0.750000  0.753769          199\n",
      "2   0.838407  0.689788  0.756871  0.689788          519\n",
      "3   0.907336  0.741325  0.815972  0.741325          317\n",
      "4   0.908397  0.918919  0.913628  0.918919          259\n",
      "[[380  30  64  18  12]\n",
      " [ 40 150   3   2   4]\n",
      " [134  19 358   2   6]\n",
      " [ 79   0   1 235   2]\n",
      " [ 16   2   1   2 238]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.71\n",
      "the precision is 0.76\n",
      "the recall is 0.73\n",
      "the f1 is 0.74\n",
      "   precision    recall        f1  accuracy  num_samples\n",
      "0   0.591265  0.523810  0.555497  0.523810         1008\n",
      "1   0.800604  0.667506  0.728022  0.667506          397\n",
      "2   0.629154  0.802505  0.705334  0.802505         1038\n",
      "3   0.897683  0.734597  0.807993  0.734597          633\n",
      "4   0.888258  0.905405  0.896750  0.905405          518\n",
      "[[528  42 385  30  23]\n",
      " [ 59 265  59   6   8]\n",
      " [163  19 833  14   9]\n",
      " [115   2  32 465  19]\n",
      " [ 28   3  15   3 469]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.74\n",
      "the precision is 0.78\n",
      "the recall is 0.75\n",
      "the f1 is 0.76\n",
      "   precision    recall        f1  accuracy  num_samples\n",
      "0   0.630592  0.578042  0.603175  0.578042         1512\n",
      "1   0.827292  0.652101  0.729323  0.652101          595\n",
      "2   0.662434  0.804110  0.726429  0.804110         1557\n",
      "3   0.875581  0.793467  0.832504  0.793467          949\n",
      "4   0.895541  0.904762  0.900128  0.904762          777\n",
      "[[ 874   54  495   57   32]\n",
      " [ 100  388   80   17   10]\n",
      " [ 246   21 1252   26   12]\n",
      " [ 123    2   43  753   28]\n",
      " [  43    4   20    7  703]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d256db83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:124: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at experiments/lightning_logs/22-02-2023--10-22-41/checkpoints/epoch=2-step=21549.ckpt\n",
      "Loaded model weights from checkpoint at experiments/lightning_logs/22-02-2023--10-22-41/checkpoints/epoch=2-step=21549.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e79b61210b2460b860c179d3bdcf274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is 0.79\n",
      "the precision is 0.83\n",
      "the recall is 0.79\n",
      "the f1 is 0.81\n",
      "   precision    recall        f1  accuracy  num_samples\n",
      "0   0.687988  0.727723  0.707298  0.727723          606\n",
      "1   0.937853  0.631179  0.754545  0.631179          263\n",
      "2   0.743976  0.769470  0.756508  0.769470          642\n",
      "3   0.838202  0.903148  0.869464  0.903148          413\n",
      "4   0.943396  0.934579  0.938967  0.934579          321\n",
      "[[441   7 118  35   5]\n",
      " [ 54 166  26  16   1]\n",
      " [125   1 494  18   4]\n",
      " [  8   3  21 373   8]\n",
      " [ 13   0   5   3 300]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(dataloaders=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e88c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the given matrix\n",
    "classes = TARGETS\n",
    "matrix = np.array([[475, 21, 94, 8, 8],\n",
    "                   [46, 203, 7, 6, 1],\n",
    "                   [153, 7, 473, 6, 3],\n",
    "                   [18, 18, 3, 373, 1],\n",
    "                   [23, 3, 1, 5, 289]])\n",
    "\n",
    "# Initialize the confusion matrix with zeros\n",
    "confusion_matrix = np.zeros((len(classes), len(classes)))\n",
    "\n",
    "# Fill the confusion matrix with values from the given matrix\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        confusion_matrix[i, j] = matrix[i, j]\n",
    "\n",
    "# Normalize the confusion matrix if needed\n",
    "#confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.matshow(confusion_matrix, cmap=plt.cm.Oranges)\n",
    "\n",
    "# Set labels for x and y axis\n",
    "ax.set_xticklabels([''] + classes, fontsize=12)\n",
    "ax.set_yticklabels([''] + classes, fontsize=12)\n",
    "\n",
    "# Set the title and axis labels\n",
    "ax.set_title('Confusion Matrix', fontsize=16)\n",
    "ax.set_xlabel('Predicted Label', fontsize=14)\n",
    "ax.set_ylabel('True Label', fontsize=14)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# Add text annotations to the confusion matrix\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        ax.text(j, i, int(confusion_matrix[i, j]), ha='center', va='center', color='white', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n",
    "plt.savefig('../Confusion_Matrix_Testing_Set.png', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23155e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64c008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b6400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281300ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dcaf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6454bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# example target and output lists\n",
    "targets = [0, 1, 2, 3, 4, 0, 1, 2, 3, 4]\n",
    "outputs = [0, 1, 1, 3, 4, 0, 2, 2, 3, 4]\n",
    "\n",
    "def classification_metrics(targets, outputs):\n",
    "    # compute confusion matrix\n",
    "    cm = confusion_matrix(targets, outputs)\n",
    "    \n",
    "    # compute total number of samples for each class\n",
    "    total_per_class = np.sum(cm, axis=1)\n",
    "    \n",
    "    # compute number of correctly classified samples for each class\n",
    "    correct_per_class = np.diagonal(cm)\n",
    "    \n",
    "    # compute precision, recall, and f1 score for each class\n",
    "    p, r, f1, _ = precision_recall_fscore_support(targets, outputs, average=None)\n",
    "    \n",
    "    # compute accuracy for each class\n",
    "    accuracy_per_class = np.divide(correct_per_class, total_per_class, where=total_per_class!=0)\n",
    "    \n",
    "    # create a dataframe to hold the results\n",
    "    df = pd.DataFrame({\n",
    "        'precision': p,\n",
    "        'recall': r,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy_per_class,\n",
    "        'num_samples': total_per_class\n",
    "    })\n",
    "    \n",
    "    print(df)\n",
    "    print(cm)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7e0659",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_metrics(targets, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d401e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define your target and output lists\n",
    "targets = [0, 1, 2, 3, 4]\n",
    "outputs = [1, 1, 2, 3, 4]\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(targets, outputs)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Calculate classification report\n",
    "report = classification_report(targets, outputs)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb93a80",
   "metadata": {},
   "source": [
    "## Testing and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28dfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change for best one - manually check which one is the best\n",
    "best_checkpoint_path = '/Users/pierredemetz/UCL_work/COMP0082-CW/code/experiments/lightning_logs/20-02-2023--21-58-19/checkpoints/epoch=1-step=14366.ckpt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ee14af",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(resume_from_checkpoint=best_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c3ac5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6815910f3f647b1ba519b38b021b492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 7183it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierredemetz/miniconda3/envs/pierre/lib/python3.8/site-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9997225403785706, 'other'), (0.9989412426948547, 'other'), (0.9995458126068115, 'mito'), (0.9990085959434509, 'cyto'), (0.9990605711936951, 'cyto'), (0.9995036125183105, 'mito'), (0.999674916267395, 'secreted'), (0.9995205402374268, 'mito'), (0.9996706247329712, 'secreted'), (0.951432466506958, 'secreted'), (0.9990999698638916, 'cyto'), (0.9989149570465088, 'cyto'), (0.9992892146110535, 'nucleus'), (0.9989752769470215, 'cyto'), (0.9998076558113098, 'other'), (0.9994365572929382, 'nucleus'), (0.9997408986091614, 'other'), (0.9994614720344543, 'nucleus'), (0.9996789693832397, 'other'), (0.9989711046218872, 'cyto')]\n"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(model, dm)\n",
    "results = []\n",
    "for item in outputs:\n",
    "    tensor = item[1]\n",
    "    max_prob, max_target_idx = torch.max(tensor, dim=1)\n",
    "    max_target = TARGETS[max_target_idx]\n",
    "    results.append((max_prob.item(), max_target))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ef259d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, tensor([[2.6261e-05, 6.6534e-05, 4.7680e-05, 9.9972e-01, 1.3703e-04]])),\n",
       " (0, tensor([[2.8934e-04, 1.0329e-04, 6.1720e-05, 9.9894e-01, 6.0441e-04]])),\n",
       " (0, tensor([[1.7493e-04, 9.9955e-01, 5.1117e-05, 1.0878e-04, 1.1941e-04]])),\n",
       " (0, tensor([[9.9901e-01, 1.4473e-04, 7.0163e-04, 6.6101e-05, 7.8964e-05]])),\n",
       " (0, tensor([[9.9906e-01, 1.9037e-04, 5.0704e-04, 1.0551e-04, 1.3662e-04]])),\n",
       " (0, tensor([[2.0273e-04, 9.9950e-01, 5.4851e-05, 1.1594e-04, 1.2289e-04]])),\n",
       " (0, tensor([[9.2876e-05, 2.0926e-05, 1.5821e-04, 5.3080e-05, 9.9967e-01]])),\n",
       " (0, tensor([[1.7974e-04, 9.9952e-01, 4.1405e-05, 1.1627e-04, 1.4197e-04]])),\n",
       " (0, tensor([[8.7799e-05, 2.2022e-05, 1.5982e-04, 5.9769e-05, 9.9967e-01]])),\n",
       " (0, tensor([[4.6848e-02, 2.7798e-04, 1.1007e-03, 3.4123e-04, 9.5143e-01]])),\n",
       " (0, tensor([[9.9910e-01, 1.5329e-04, 5.8158e-04, 5.1600e-05, 1.1361e-04]])),\n",
       " (0, tensor([[9.9891e-01, 1.0675e-04, 8.5326e-04, 5.5866e-05, 6.9128e-05]])),\n",
       " (0, tensor([[5.6326e-04, 2.0238e-05, 9.9929e-01, 1.8695e-05, 1.0864e-04]])),\n",
       " (0, tensor([[9.9898e-01, 1.1740e-04, 7.9669e-04, 4.8323e-05, 6.2317e-05]])),\n",
       " (0, tensor([[3.4357e-05, 6.2031e-05, 3.4956e-05, 9.9981e-01, 6.1037e-05]])),\n",
       " (0, tensor([[4.2671e-04, 1.9761e-05, 9.9944e-01, 2.4975e-05, 9.2038e-05]])),\n",
       " (0, tensor([[4.6324e-05, 3.5689e-05, 4.4463e-05, 9.9974e-01, 1.3268e-04]])),\n",
       " (0, tensor([[4.0254e-04, 1.8712e-05, 9.9946e-01, 2.4449e-05, 9.2881e-05]])),\n",
       " (0, tensor([[3.0362e-05, 5.8792e-05, 5.6803e-05, 9.9968e-01, 1.7511e-04]])),\n",
       " (0, tensor([[9.9897e-01, 1.2489e-04, 7.3334e-04, 8.7192e-05, 8.3478e-05]]))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd25071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ca22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510ddae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80687ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc613e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee6a125a",
   "metadata": {},
   "source": [
    "## LEGACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dca1b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_list = ['cyto', 'mito', 'nucleus','other', 'secreted']\n",
    "n_classes = 5\n",
    "\n",
    "protein_classifier = ProteinClassifier(n_classes, target_list)\n",
    "protein_classifier = protein_classifier.load_from_checkpoint(\n",
    "    checkpoint_path=best_checkpoint_path,\n",
    "    n_classes=n_classes,\n",
    "    target_list=target_list\n",
    ")\n",
    "\n",
    "protein_classifier.eval()\n",
    "protein_classifier.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab351ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\n",
    "  \"seq\": \"M S T D T G V S L P S Y E E D Q G S K L I R K A K E A P F V P V G I A G F A A I V A Y G L Y K L K S R G N T K M S I H L I H M R V A A Q G F V V G A M T V G M G Y S M Y R E F W A K P K P\",\n",
    "}\n",
    "\n",
    "predictions = protein_classifier.predict_step(sample, batch_idx=0)\n",
    "\n",
    "print(\"Sequence Localization Ground Truth is: {} - prediction is: {}\".format('Mitochondrion',predictions['predicted_label']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae99666",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e991be6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d55e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada2eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertModel.from_pretrained(\"Rostlab/prot_bert\")\n",
    "sequence_Example = \"A E T C Z A O\"\n",
    "sequence_Example = re.sub(r\"[UZOB]\", \"X\", sequence_Example)\n",
    "encoded_input = tokenizer(sequence_Example, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6245952",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print(x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92310d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator_registry=torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelertorch.backends.mps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MPSAccelerator.register_accelerators(device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f450e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74d3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "!arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511a9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
